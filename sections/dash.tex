\section{Unordered Delivery in MPEG-DASH}
\label{sec:transport}

MPEG-DASH is designed for an ordered transport protocol. Adapting it for an
unordered transport protocol requires several considerations. These
changes happen in two broad areas: the HTTP request and response semantics, and the rate
adaptation algorithms. We consider both of these in turn below.

\begin{figure}
  \centering
  \includegraphics[width=\columnwidth]{figures/terminology2.pdf}
  \caption{Illustration of the terminology used in this paper and also the encapsulation of data for transport.}
  \label{fig:terminology}
\end{figure}

Given that our approach spans multiple layers of the stack, we must use carefully defined
terminology. The MPEG-DASH standard sends \emph{chunks}; these are groups of video
\emph{frames} that have the same duration. In our approach, the server will send these
using TCP Hollywood \emph{messages}. A chunk may be split across more than one message,
but a message will never contain data from more than one chunk. Finally, messages are
send in TCP \emph{segments}; a segment may contain data from more than one message, and
may contain only some of the data for a message.
Figure \ref{fig:terminology} illustrates this terminology.

\subsection{HTTP Request/Response Semantics}

As discussed in the previous section, the transmission unit of TCP Hollywood is a message:
complete messages are delivered to the application when they arrive. Care must be taken in
deciding what should be sent in each message: if a message is too large, then its loss
will have a greater impact on the application's quality-of-experience; too small, and the
ratio of payload to header will be low. Sending an entire chunk per message means that,
in the event a segment that makes up the message is lost, upwards of 1 second of video
data is not delivered to the application. Sending a single video frame is the
other extreme: we minimise the impact of loss on QoE, but reduce the efficiency of our
application, by sending a TCP/IP header per video frame. As a result, we opt for a
compromise: we send fixed-size (1400 byte) messages. This reduces the impact of loss 
(though not minimally), while amortising the header across a larger payload.

TCP Hollywood supports multi-streaming over a single TCP connection, allowing for the
separation of the control and data channels. We use separate streams for HTTP request and
response headers, sending each as separate TCP Hollywood messages. This allows the client
to request later chunks while earlier chunks are still downloading. The server still sends
chunks sequentially, but does not have to wait for the next request to arrive; this is
especially useful in high latency networks. Figure \ref{fig:hollywood_download}
illustrates chunk retrieval with HTTP over both standard TCP and TCP Hollywood.

Our use of multi-streaming in TCP Hollywood is similar to HTTP/1.1 pipelining and bundle
requests in HLS \cite{muller2012evaluation}. However, these approaches require quality
estimates to be submitted for all chunks at request time. This means that a quality
estimate may be two or more chunk durations old before being used at the server.
Fluctuations in network conditions in the interval between request and response mean that
these quality estimates can be incorrect. Under TCP Hollywood, requests can be sent while
chunks are downloading, allowing for the server to receive a more recent and accurate
estimate of network conditions. This reduces the likelihood of an under or over estimation
of performance, improving quality-of-experience. Further, HTTP/1.1 pipelining suffers
from transport-layer head-of-line blocking in standard TCP, which is eliminated under TCP Hollywood.

Finally, TCP Hollywood can discard late messages and continue play-out,
thereby limiting stall events only to those cases when the play-out buffer is completely
empty.

\begin{figure}
    \centering
    \includegraphics[width=\columnwidth]{figures/tcph-download.pdf}
    \caption{An illustration of chunk download with HTTP over TCP and over TCP Hollywood}
    \label{fig:hollywood_download}
    % FIXME: what are the light blue and light green shaded rectangles in this figure? [csp]
\end{figure}

The requested chunks of video are transmitted on a single stream, using fixed size
messages. As the server is content-agnostic, it is unable to set an expiry time for messages, and
all messages are sent reliably. A content-aware server would set this to the relative presentation time of the chunk.
For the sake of simplicity, audio
stream is not used. Each message is appended with a monotonically increasing sequence
number and a stream offset. The stream offset is the offset of the last byte of the
message within this stream, where a stream includes all chunks that have been transmitted
previously. Both fields are used by the receiver to reorder the messages and detect
losses. We expanded the function of the play-out buffer to include de-jittering and
reordering of the incoming messages.

% FIXME: explain why MP4 is not suitable [csp]
It is also important to use a media format that is tolerant of packet losses. Hence, the
commonly used ISO Base Media File Format (MP4) is not suitable for TCP Hollywood, so we
use MPEG Transport streams (TS) instead. The use of MPEG-TS streams is allowed as part of
the MPEG-DASH standard and are also used by HLS.

\subsection{Rate Adaptation Algorithms}

Performance of a MPEG-DASH system relies heavily on a good rate adaptation algorithm.
Such algorithms use application-level measurements such as buffer length, throughput, time to
download a chunk, or a combination of these to select an appropriate quality for
download \cite{beben2016abma+, spiteri2016bola, li2014probe}. There is some consensus
among researchers that buffer-based algorithms are more performant and reliable in a wider
variety of network conditions than other algorithms 
\cite{huang2015buffer, karagkioules2017comparative}.

Our TCP Hollywood-based MPEG-DASH client uses a modified version of the open-source BOLA 
(Buffer Occupancy based Lyapunov Algorithm) rate adaptation algorithm \cite{spiteri2016bola}. 
BOLA is part of the MPEG-DASH reference
client, dash.js.\footnote{\url{https://github.com/Dash-Industry-Forum/dash.js/wiki}}
BOLA uses the amount of video currently buffered to calculate the quality level (bit-rate
level) for the next chunk. For live video, where buffer sizes are limited, the algorithm
uses throughput estimates to further reduce over-estimation and stalling. In the presence
of packet loss and duplication, that is possible with TCP Hollywood, the calculation 
mechanisms for both measurements have to be modified. For a standard MPEG-DASH client,
the HTTP request for the next chunk is always sent 
during the download of the current chunk. For our TCP Hollywood-based client, we
introduce a new parameter, $Rx_{T}$, the receive ratio threshold. We modify
the rate adaptation algorithm so that if $Rx_{T}$ of the
bytes from a chunk have been received and the buffer is not filled to capacity, 
it estimates the quality of the next chunk based on the \emph{current} measurements and
sends a GET request to the server. Throughput is measured from the time the HTTP response
of a chunk arrives until $Rx_{T}$ is reached, excluding any duplicates. We experimented
with different values of $Rx_{T}$ and found 0.9 to be a suitable ratio. The full duration
of the chunk is used when calculating the buffer level, even though the entire chunk has
not been downloaded. With an $Rx_{T}$ value of 0.9, this is a safe assumption: only 10\%
of the chunk remains to be downloaded, with some data in-flight, and a limited number of
messages that may delayed (and subsequently discarded by TCP Hollywood if
they miss their deadline).
% FIXME: probably outside the scope of the initial submission, but it would
% be appropriate to describe the experiments and results that led to the
% choice of 0.9 as a parameter [csp]

% FIXME: "uses an effective buffer level" to do what? [csp]
BOLA uses an effective buffer level in the event that the chunk download is slowed by
the availability of the next chunk at the server (e.g., it has not been captured yet, as
in live scenarios) or by the size of the play-out buffer. In this case, as the buffer level has not
been limited by network conditions, the client is able to request higher quality chunks.
Therefore, the effective buffer level is the current buffer level, plus the time spent
waiting before downloading the next chunk. With TCP Hollywood, messages may be discarded
due to late arrival. If the buffer contains more than one chunk, we reduce the length of
effective buffer level by one chunk duration.


\begin{algorithm}
\begin{algorithmic}[1]
\Procedure{DownloadStream}{}
\State $\textit{n} \gets \textit{index of current chunk}$
\State $N \gets \textit{Total number of chunks}$
\State $q \gets \textit{Quality of the chunk}$
\State ${InitializeMetrics()}$
\While {$\text{n} < \text{N}$}
\State ${q \gets RunAlgorithm()}$
\State ${DownloadChunk(q, n)}$
\State ${UpdateMetricsUsingLastDownload()}$
\EndWhile
\EndProcedure
\end{algorithmic}
\caption{DASH Client Operation with TCP}\label{euclid}
\end{algorithm}
 

\begin{algorithm}
\caption{DASH Client Operation with QUIC}\label{euclid}
\begin{algorithmic}[1]
\Procedure{DownloadStream}{}
\State $\textit{n} \gets \textit{index of current chunk}$
\State $N \gets \textit{Total number of chunks}$
\State $q \gets \textit{Quality of the chunk}$
\State $S_n^q \gets \textit{Size of chunk with index n and quality q}$
\State $B_n^q  \gets \textit{Bytes received for chunk with index n and quality q }$
\State $Rx_T \gets Minimum Receive Threshold$
\State ${InitializeMetrics()}$
\While {$\text{n} < \text{N}$}
\State ${q \gets RunAlgorithm()}$
\State $InitiateChunkDownload(q, n)$
\While {$B_n^q < Rx_T * S_n^q$}
\State $Wait()$
\EndWhile
\State ${UpdateMetricsUsingLastDownload()}$
\EndWhile
\EndProcedure
\end{algorithmic}
\end{algorithm}



%
%For the latter, we use the parameter rxratio (Receive ratio); the receiver will stop
%actively receiving a chunk if it has already received rxratio times the total bytes in
%the chunk and move on to estimating quality and requesting the next chunk. Since we use a
%buffer based algorithm, we still assume that we have received the entire chunk while
%calculating the quality of the next chunk. Note that the remaining chunk is still being
%received passively, which means that the data is not used in throughput calculations for
%the adaptation algorithm. 
%
